{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "\n",
    "def train_classifier(features_train, features_test, label_train, label_test, classifier):\n",
    "    if classifier == \"Logistic_Regression\":\n",
    "        model = LogisticRegression(C=1.)\n",
    "    elif classifier == \"Naive_Bayes\":\n",
    "        model = MultinomialNB()\n",
    "    elif classifier == \"SVM\":\n",
    "        model = SVC()\n",
    "    elif classifier == \"Linear\":\n",
    "        model = LinearRegression()    \n",
    "    elif classifier == \"Random_Forest\":\n",
    "        model = RandomForestClassifier(n_estimators=400, random_state=11)\n",
    "    elif classifier == \"Kmeans\":\n",
    "        knn = neighbors.KNeighborsRegressor()\n",
    "        params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "        model = GridSearchCV(knn, params, cv=5)\n",
    "    else:\n",
    "        print(\"Incorrect Selection Of Classifier\")\n",
    "\n",
    "    model.fit(features_train, label_train)\n",
    "    print(\"Model Fitting Done\")\n",
    "\n",
    "    fileName = './Sentiment_models/' + classifier + '.pickle'\n",
    "    with open(fileName, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(\"Pickle File Created %s\" % fileName)\n",
    "\n",
    "    accuracy = model.score(features_test, label_test)\n",
    "    print(\"Accuracy Is:\", accuracy)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read\n"
     ]
    }
   ],
   "source": [
    "#ID,Title,Air_Date,Production_Code,Season,Episode_No.,Total_Episodes_Till_Now,US_Viewers_In_Millions,Views,IMDB_Rating,IMDB_Votes,Image_URL,Video_URL,Retweets,Favorites,Vader_Score,Sentiment_Score,Tweets_Per_Day,Unique_Users\n",
    " \n",
    "# fileName=\"simpsons_episodes.csv\"\n",
    "# my_df = pd.read_csv(fileName)\n",
    "\n",
    "train = pd.read_csv(\"simpsons_episodes_train.csv\")\n",
    "test = pd.read_csv(\"simpsons_episodes_test.csv\")\n",
    "\n",
    "\n",
    "print(\"File read\")\n",
    "for i in ['ID','Title','Air_Date','Production_Code','Season','Episode_No.',\n",
    "          'Total_Episodes_Till_Now','Image_URL','Video_URL']:\n",
    "    # del my_df[i]\n",
    "    del train[i]\n",
    "    del test[i]\n",
    "# print(my_df.head())\n",
    "# my_df_temp =my_df   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 110 entries, 0 to 109\nData columns (total 10 columns):\nUS_Viewers_In_Millions    110 non-null float64\nViews                     110 non-null float64\nIMDB_Rating               110 non-null float64\nIMDB_Votes                110 non-null float64\nRetweets                  110 non-null float64\nFavorites                 110 non-null float64\nVader_Score               110 non-null float64\nSentiment_Score           110 non-null float64\nTweets_Per_Day            110 non-null float64\nUnique_Users              110 non-null float64\ndtypes: float64(10)\nmemory usage: 8.7 KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 22 entries, 0 to 21\nData columns (total 10 columns):\nUS_Viewers_In_Millions    22 non-null float64\nViews                     22 non-null float64\nIMDB_Rating               22 non-null float64\nIMDB_Votes                22 non-null float64\nRetweets                  22 non-null float64\nFavorites                 22 non-null float64\nVader_Score               22 non-null float64\nSentiment_Score           22 non-null float64\nTweets_Per_Day            22 non-null float64\nUnique_Users              22 non-null float64\ndtypes: float64(10)\nmemory usage: 1.8 KB\n"
     ]
    }
   ],
   "source": [
    "# my_df.dropna(inplace=True)\n",
    "# my_df.reset_index(drop=True,inplace=True)\n",
    "# my_df.info()\n",
    "train.dropna(inplace=True)\n",
    "train.reset_index(drop=True,inplace=True)\n",
    "train.info()\n",
    "test.dropna(inplace=True)\n",
    "test.reset_index(drop=True,inplace=True)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-64a7be7e3550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m X = my_df.loc[:, ['Views','IMDB_Votes','IMDB_Rating','Vader_Score','Sentiment_Score'\n\u001b[0m\u001b[0;32m      2\u001b[0m                   ,'Retweets','Favorites','Tweets_Per_Day','Unique_Users']]\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'US_Viewers_In_Millions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_df' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "X = my_df.loc[:, ['Views','IMDB_Votes','IMDB_Rating','Vader_Score','Sentiment_Score'\n",
    "                  ,'Retweets','Favorites','Tweets_Per_Day','Unique_Users']]\n",
    "\n",
    "y = my_df.loc[:, ['US_Viewers_In_Millions']]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a00fb30a35d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# let's print shape of each train and testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape of X_train: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape of y_train: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape of X_test: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=0)\n",
    "# let's print shape of each train and testing\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Started\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-08ab048c7ab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model Training Started\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Linear\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model Training Complete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(\"Model Training Started\")\n",
    "algorithm = \"Linear\"\n",
    "model = train_classifier(X_train,X_test, y_train, y_test, algorithm)\n",
    "print(\"Model Training Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 6673168089471086769]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n [49. 64.]]\n[node {\n  name: \"MatMul_2\"\n  op: \"Const\"\n  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 2\n          }\n          dim {\n            size: 2\n          }\n        }\n        tensor_content: \"\\000\\000\\260A\\000\\000\\340A\\000\\000DB\\000\\000\\200B\"\n      }\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"MatMul_2\"\n  }\n}\nnode {\n  name: \"_retval_MatMul_2_0_0\"\n  op: \"_Retval\"\n  input: \"MatMul_2\"\n  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"index\"\n    value {\n      i: 0\n    }\n  }\n  experimental_debug_info {\n    original_node_names: \"_retval_MatMul_2_0_0\"\n  }\n}\nlibrary {\n}\nversions {\n  producer: 27\n}\n]\n"
     ]
    }
   ],
   "source": [
    "# Test with a simple computation\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.Session()\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n",
    "# If you have gpu you can try this line to compute b with your GPU\n",
    "#with tf.device('/gpu:0'):    \n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "print(sess.run(c))\n",
    "\n",
    "# Runs the op.\n",
    "# Log information\n",
    "options = tf.RunOptions(output_partition_graphs=True)\n",
    "metadata = tf.RunMetadata()\n",
    "c_val = sess.run(c, options=options, run_metadata=metadata)\n",
    "\n",
    "print(metadata.partition_graphs)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data with numerical features: (110, 10)\nShape of the test data with numerical features: (22, 10)\n\nList of features contained our dataset: ['US_Viewers_In_Millions', 'Views', 'IMDB_Rating', 'IMDB_Votes', 'Retweets', 'Favorites', 'Vader_Score', 'Sentiment_Score', 'Tweets_Per_Day', 'Unique_Users']\nList of features contained our dataset: ['US_Viewers_In_Millions', 'Views', 'IMDB_Rating', 'IMDB_Votes', 'Retweets', 'Favorites', 'Vader_Score', 'Sentiment_Score', 'Tweets_Per_Day', 'Unique_Users']\nNumber of rows:  110\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# train = pd.read_csv('../input/train.csv')\n",
    "# train, test= train_test_split(my_df_temp, test_size = 0.1, random_state=0)\n",
    "\n",
    "train.fillna(0,inplace=True)\n",
    "\n",
    "test.fillna(0,inplace=True)\n",
    "\n",
    "print('Shape of the train data with numerical features:', train.shape)\n",
    "print('Shape of the test data with numerical features:', test.shape)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"List of features contained our dataset:\",list(train.columns))\n",
    "print(\"List of features contained our dataset:\",list(test.columns))\n",
    "\n",
    "print(\"Number of rows: \", train.shape[0])\n",
    "rows =train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US_Viewers_In_Millions', 'Views', 'IMDB_Rating', 'IMDB_Votes', 'Retweets', 'Favorites', 'Vader_Score', 'Sentiment_Score', 'Tweets_Per_Day', 'Unique_Users']\nnvjhv\n['Views', 'IMDB_Rating', 'IMDB_Votes', 'Retweets', 'Favorites', 'Vader_Score', 'Sentiment_Score', 'Tweets_Per_Day', 'Unique_Users']\nHello1\nHello1\nHello1\n   US_Viewers_In_Millions     Views  IMDB_Rating  IMDB_Votes  Retweets  \\\n0               8650000.0  0.167802     0.621622    0.130332       0.0   \n1              14620000.0  0.267141     0.594595    0.214455       0.0   \n2               5110000.0  0.283668     0.702703    0.190758       0.0   \n3               5870000.0  0.386112     0.621622    0.182464       0.0   \n4               6080000.0  0.288802     0.567568    0.148104       0.0   \n\n   Favorites  Vader_Score  Sentiment_Score  Tweets_Per_Day  Unique_Users  \n0        0.0     0.395580         0.000000        0.000000      0.000000  \n1        0.0     0.396548         0.052632        0.007458      0.003247  \n2        0.0     0.395580         0.000000        0.011160      0.012853  \n3        0.0     0.395580         0.000000        0.006749      0.006313  \n4        0.0     0.395580         0.000000        0.007012      0.003157  \n      Views  IMDB_Rating  IMDB_Votes  Retweets  Favorites  Vader_Score  \\\n0  0.061716     0.583333    0.182648       0.0        0.0     0.134582   \n1  1.000000     0.833333    1.000000       0.0        0.0     1.000000   \n2  0.125851     0.916667    0.095890       0.0        0.0     0.134582   \n3  0.021693     0.333333    0.082192       0.0        0.0     0.134582   \n4  0.000000     0.250000    0.127854       0.0        0.0     0.134582   \n\n   Sentiment_Score  Tweets_Per_Day  Unique_Users  \n0             0.25        0.052714      0.000000  \n1             1.00        0.053760      0.117798  \n2             0.25        0.240917      0.024938  \n3             0.25        0.035288      0.002378  \n4             0.25        0.089309      0.006951  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "col_train = list(train.columns)\n",
    "print(col_train)\n",
    "col_train_bis = list(train.columns)\n",
    "print(\"nvjhv\")\n",
    "col_train_bis.remove('US_Viewers_In_Millions')\n",
    "print(col_train_bis)\n",
    "viewership_temp = train['US_Viewers_In_Millions']\n",
    "mat_train = np.matrix(train)\n",
    "mat_test  = np.matrix(test)\n",
    "mat_new = np.matrix(test.drop('US_Viewers_In_Millions',axis = 1))\n",
    "mat_y = np.array(train.US_Viewers_In_Millions).reshape((rows,1))\n",
    " \n",
    "prepro_y = MinMaxScaler()\n",
    "prepro_y.fit(mat_y)\n",
    "print(\"Hello1\")\n",
    "prepro = MinMaxScaler()\n",
    "prepro.fit(mat_train)\n",
    "print(\"Hello1\")\n",
    "prepro_test = MinMaxScaler()\n",
    "prepro_test.fit(mat_new)\n",
    "print(\"Hello1\")\n",
    "train = pd.DataFrame(prepro.transform(mat_train),columns = col_train)\n",
    "train['US_Viewers_In_Millions']= viewership_temp \n",
    "\n",
    "test  = pd.DataFrame(prepro_test.transform(mat_new),columns = col_train_bis)\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Views  IMDB_Rating  IMDB_Votes  Retweets  Favorites  Vader_Score  \\\n65  0.278535     0.729730    0.144550       0.0        0.0     0.395580   \n26  0.329669     0.675676    0.136256       0.0        0.0     0.395580   \n22  0.356964     0.648649    0.228673       0.0        0.0     0.395580   \n31  0.292382     0.540541    0.117299       0.0        0.0     0.395580   \n47  0.344293     0.675676    0.215640       0.0        0.0     0.374128   \n\n    Sentiment_Score  Tweets_Per_Day  Unique_Users  US_Viewers_In_Millions  \n65         0.105263        0.115439      0.092175               7440000.0  \n26         0.052632        0.053585      0.024571               6500000.0  \n22         0.000000        0.039074      0.017236               9540000.0  \n31         0.000000        0.067752      0.048597               6140000.0  \n47         0.000000        0.164039      0.055750              11480000.0  \nDone\n"
     ]
    }
   ],
   "source": [
    "# List of features\n",
    "COLUMNS = col_train\n",
    "FEATURES = col_train_bis\n",
    "LABEL = \"US_Viewers_In_Millions\"\n",
    "\n",
    "# Columns for tensorflow\n",
    "feature_cols = [tf.contrib.layers.real_valued_column(k) for k in FEATURES]\n",
    "\n",
    "# Training set and Prediction set with the features to predict\n",
    "training_set = train[COLUMNS]\n",
    "prediction_set = train.US_Viewers_In_Millions\n",
    "\n",
    "# Train and Test \n",
    "x_train, x_test, y_train, y_test = train_test_split(training_set[FEATURES] , prediction_set, test_size=0.2, random_state=42)\n",
    "y_train = pd.DataFrame(y_train, columns = [LABEL])\n",
    "training_set = pd.DataFrame(x_train, columns = FEATURES).merge(y_train, left_index = True, right_index = True)\n",
    "print(training_set.head())\n",
    "\n",
    "# Training for submission\n",
    "training_sub = training_set[col_train]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Views  IMDB_Rating  IMDB_Votes  Retweets  Favorites  Vader_Score  \\\n78  0.323033     0.486486    0.046209       0.5        0.5      0.39558   \n10  0.278109     0.648649    0.165877       0.0        0.0      0.39558   \n4   0.288802     0.567568    0.148104       0.0        0.0      0.39558   \n84  0.279085     0.702703    0.084123       0.0        0.0      0.39558   \n64  0.342690     0.540541    0.069905       0.0        0.0      0.41947   \n\n    Sentiment_Score  Tweets_Per_Day  Unique_Users  US_Viewers_In_Millions  \n78         0.000000        0.171416      0.076392               4160000.0  \n10         0.052632        0.012038      0.005178               5940000.0  \n4          0.000000        0.007012      0.003157               6080000.0  \n84         0.052632        0.147663      0.064629               4080000.0  \n64         0.052632        0.169349      0.072055               7460000.0  \n"
     ]
    }
   ],
   "source": [
    "# Same thing but for the test set\n",
    "y_test = pd.DataFrame(y_test, columns = [LABEL])\n",
    "testing_set = pd.DataFrame(x_test, columns = FEATURES).merge(y_test, left_index = True, right_index = True)\n",
    "print(testing_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "regressor = tf.contrib.learn.DNNRegressor(feature_columns=feature_cols, \n",
    "                                          activation_fn = tf.nn.relu, hidden_units=[200, 100, 50, 25, 12])#,\n",
    "                                         #optimizer = tf.train.GradientDescentOptimizer( learning_rate= 0.1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of training\n",
    "training_set.reset_index(drop = True, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_set, pred = False):\n",
    "    \n",
    "    if pred == False:\n",
    "        \n",
    "        feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n",
    "        labels = tf.constant(data_set[LABEL].values)\n",
    "        \n",
    "        return feature_cols, labels\n",
    "\n",
    "    if pred == True:\n",
    "        feature_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}\n",
    "        \n",
    "        return feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "regressor.fit(input_fn=lambda: input_fn(training_set), steps=2000)\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3624016800000.0, 'global_step': 2000}\nDone\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set created by train_test_split\n",
    "ev = regressor.evaluate(input_fn=lambda: input_fn(testing_set), steps=1)\n",
    "print(ev)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss on the testing set: 3624016805888.000000\n"
     ]
    }
   ],
   "source": [
    "# Display the score on the testing set\n",
    "# 0.002X in average\n",
    "loss_score1 = ev[\"loss\"]\n",
    "print(\"Final Loss on the testing set: {0:f}\".format(loss_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4342217.5, 7331916.5, 6755606.5, 6244709.5, 5348859.5, 5674939.5, 6225052.0, 7452670.5, 5342902.5, 7329768.5, 5099173.0, 9320111.0, 7245795.5, 463777.22, 7352783.5, 4954099.0, 5496182.0, 4901030.0, 5440801.5, 8171113.0, 6936676.5, 6650694.0]\n<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y = regressor.predict(input_fn=lambda: input_fn(testing_set))\n",
    "print(list(y))\n",
    "\n",
    "predictions = list(itertools.islice(y, testing_set.shape[0]))\n",
    "print(type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (22,1)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-8a79c7dedf1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepro_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (22,1)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "predictions = pd.DataFrame(prepro_y.inverse_transform(np.array(predictions).reshape(22,1)),columns = ['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "reality = pd.DataFrame(prepro.inverse_transform(testing_set), columns = [COLUMNS]).US_Viewers_In_Millions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('xtick', labelsize=30) \n",
    "matplotlib.rc('ytick', labelsize=30) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(50, 40))\n",
    "plt.interactive(False)\n",
    "plt.style.use('ggplot')\n",
    "plt.plot(predictions.values, reality.values, 'ro')\n",
    "plt.xlabel('Predictions', fontsize = 30)\n",
    "plt.ylabel('Reality', fontsize = 30)\n",
    "plt.title('Predictions x Reality on dataset Test', fontsize = 30)\n",
    "ax.plot([reality.min(), reality.max()], [reality.min(), reality.max()], 'k--', lw=4)\n",
    "plt.show()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
